{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecba0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Step 1\")\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "digits\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba15f938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2\n",
      "The max depth is 1\n",
      "[0.2        0.2        0.19498607 0.19498607 0.19777159]\n",
      "The mean is 0.19754874651810586\n",
      "The max depth is 2\n",
      "[0.31666667 0.30555556 0.31197772 0.31754875 0.3091922 ]\n",
      "The mean is 0.3121881770349737\n",
      "The max depth is 3\n",
      "[0.43055556 0.38055556 0.4902507  0.45961003 0.40389972]\n",
      "The mean is 0.43297431135871245\n",
      "The max depth is 4\n",
      "[0.51944444 0.46388889 0.59052925 0.61281337 0.53481894]\n",
      "The mean is 0.5442989786443826\n",
      "The max depth is 5\n",
      "[0.63888889 0.49444444 0.67409471 0.72980501 0.62116992]\n",
      "The mean is 0.6316805942432683\n",
      "The max depth is 6\n",
      "[0.73888889 0.59444444 0.75487465 0.77715877 0.71866295]\n",
      "The mean is 0.7168059424326834\n",
      "The max depth is 7\n",
      "[0.76388889 0.67777778 0.77437326 0.77437326 0.75487465]\n",
      "The mean is 0.7490575673166202\n",
      "The max depth is 8\n",
      "[0.77777778 0.70277778 0.79665738 0.83008357 0.78551532]\n",
      "The mean is 0.7785623645930052\n",
      "The max depth is 9\n",
      "[0.76666667 0.71388889 0.79108635 0.84401114 0.78551532]\n",
      "The mean is 0.7802336737852058\n",
      "The max depth is 10\n",
      "[0.775      0.725      0.80222841 0.84958217 0.78272981]\n",
      "The mean is 0.786908077994429\n",
      "[0.19754874651810586, 0.3121881770349737, 0.43297431135871245, 0.5442989786443826, 0.6316805942432683, 0.7168059424326834, 0.7490575673166202, 0.7785623645930052, 0.7802336737852058, 0.786908077994429]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Step 2\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "x = digits['data']\n",
    "y = digits['target']\n",
    "the_means = []\n",
    "\n",
    "# \n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "cross_val_score(clf, x, y, cv=5)\n",
    "\n",
    "# clf = DecisionTreeClassifier(max_depth = 1, random_state=0)\n",
    "# cross_val_score(clf, x, y, cv=5)\n",
    "from statistics import mean \n",
    "for i in range(10):\n",
    "    clf = DecisionTreeClassifier(max_depth = i + 1, random_state=0)\n",
    "    print(\"The max depth is\", i + 1)\n",
    "    five_array = cross_val_score(clf, x, y, cv=5)\n",
    "    cvs_mean = mean(five_array)\n",
    "    the_means.append(cvs_mean)\n",
    "    print(five_array)\n",
    "    print(\"The mean is\", cvs_mean)\n",
    "\n",
    "print(the_means)\n",
    "\n",
    "\n",
    "# importing the library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# data to be plotted\n",
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "y = the_means\n",
    " \n",
    "# plotting\n",
    "plt.title(\"\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(x, y, color =\"purple\")\n",
    "plt.show()\n",
    "\n",
    "# How does the average cross validation error change for each of these depths?\n",
    "# The average cross validation error decreases as more depth is added to the decision tree.\n",
    "print(\"The average cross validation error decreases as more depth is added to the decision tree.\")\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e5b954",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3\n",
      "[6 9 3 7 2 2 4 2 5 2 2 4 4 0 4 2 3 7 8 8 4 3 9 7 2 6 3 2 6 3 4 9 1 4 4 6 9\n",
      " 4 7 6 6 9 1 3 6 1 3 0 6 5 5 1 5 4 6 0 3 0 0 8 5 4 5 2 4 5 7 0 7 5 9 5 5 4\n",
      " 7 0 8 4 5 9 9 0 2 3 8 0 6 4 4 9 1 2 8 3 5 2 9 1 4 7 4 3 4 3 1 4 5 4 4 2 9\n",
      " 7 4 4 4 9 2 7 6 7 2 6 9 4 2 7 8 7 5 4 7 5 7 9 0 6 6 4 2 8 0 9 4 6 9 1 4 9\n",
      " 0 5 5 6 6 0 6 4 2 9 3 1 7 2 9 0 4 5 8 6 5 4 9 8 4 2 1 9 7 7 2 2 3 9 2 0 3\n",
      " 8 2 5 6 9 9 4 4 5 4 8 3 1 4 1 5 9 5 7 8 9 4 8 1 5 4 4 9 6 1 8 6 0 4 5 2 7\n",
      " 1 6 4 5 6 1 3 2 3 6 7 1 5 1 4 7 6 4 8 5 5 3 5 2 8 1 7 7 7 5 2 2 2 3 5 8 8\n",
      " 3 6 0 9 7 7 0 1 0 4 5 8 5 3 6 0 1 1 0 0 3 6 5 9 7 3 3 5 9 5 1 5 3 3 2 0 5\n",
      " 9 3 4 0 2 4 6 4 3 4 5 0 4 2 1 3 1 4 2 1 7 0 4 1 2 1 8 8 7 0 6 4 8 8 5 1 8\n",
      " 4 3 8 7 9 8 4 0 8 2 0 7 9 1 9 5 2 7 7 1 8 7 4 3 8 3 3 6 0 0 3 0 5 0 0 4 1\n",
      " 2 8 1 5 9 6 3 4 8 8 4 2 3 4 9 8 8 4 0 6 2 3 7 1 4 4 2 2 1 1 1 4 7 1 8 3 4\n",
      " 0 5 4 9 4 2 7 6 3 4 0 3 9 4 4 9 7 4 2 2 9 0 7 5 8 3 6 3 1 6 9 5 0 1 5 3 3\n",
      " 3 3 6 2 6 5 5 2 0 8 7 3 7 0 2 2 3 5 8 7 3 6 5 9 4 2 5 6 3 0 7 2 1 9 8 8 1\n",
      " 0 0 2 9 9 9 5 5 7 7 1 3 5 4 6 5 2 1 1 8 7 6 9 2 0 4 4 8 8 7 1 8 1 7 1 3 5\n",
      " 3 7 0 0 1 2 6 1 4 5 8 0 6 7 7 9 5 1 7 0 7 6 8 7 1 4 6 2 8 7 4 9 0 3 9 6 6\n",
      " 1 9 9 2 9 8 1 7 4 8 5 5 9 7 7 6 8 1 3 5 5 9 5 9 2 1 1 2 2 4 4 7 1 8 1 9 4\n",
      " 9 0 1 1 8 9 8 4 2 1 1 7 2 2 3 1 7 6 3 0 6 5 2 8 5 2 8 0 9 1 2 8 1 4 1 9 2\n",
      " 4 1 6 2 0 8 1 0 6 1 7 7 8 2 8 2 6 9 5 7 1 4 8 1 2 9 8 4 3 4 0 3 5 1 8 1 1\n",
      " 0 9 0 2 4 2 1 0 3 9 2 4 0 4 1 6 5 4 0 3 1 6 6 4 1 1 7 1 0 5 8 8 5 7 0 4 7\n",
      " 6 9 3 4 5 8 1 6 5 9 3 2 2 1 8 2 4 1 0 4 2 0 8 2 6 2 1 6 8 8 2 8 7 3 5 6 2\n",
      " 1 3 9 4 6 4 6 1 4 0 2 9 7 6 0 6 5 6 4 0 3 4 1 7 4 3 0 9 2 0 1 9 2 7 0 7 0\n",
      " 7 3 6 3 4 9 2 4 3 4 9 6 6 2 7 8 5 7 3 3 3 2 9 1 5 1 2 0 7 3 9 8 7 3 1 0 8\n",
      " 4 3 2 2 5 1 3 2 3 2 0 7 6 9 7 9 4 9 6 1 4 6 7 1 8 5 8 3 6 0 2 8 3 6 1 1 4\n",
      " 2 8 1 9 6 3 6 3 5 2 5 4 8 9 0 1 7 2 2 9 8 3 1 4 3 8 6 6 7 9 4 7 2 4 0 1 1\n",
      " 6 1 1 6 2 4 8 1 8 5 2]\n",
      "[6 9 3 7 2 1 5 2 5 2 1 9 4 0 4 2 3 7 8 8 4 3 9 7 5 6 3 5 6 3 4 9 1 4 4 6 9\n",
      " 4 7 6 6 9 1 3 6 1 3 0 6 5 5 1 9 5 6 0 9 0 0 1 0 4 5 2 4 5 7 0 7 5 9 5 5 4\n",
      " 7 0 4 5 5 9 9 0 2 3 8 0 6 4 4 9 1 2 8 3 5 2 9 0 4 4 4 3 5 3 1 3 5 9 4 2 7\n",
      " 7 4 4 1 9 2 7 8 7 2 6 9 4 0 7 2 7 5 8 7 5 7 7 0 6 6 4 2 8 0 9 4 6 9 9 6 9\n",
      " 0 3 5 6 6 0 6 4 3 9 3 9 7 2 9 0 4 5 3 6 5 9 9 8 4 2 1 3 7 7 2 2 3 9 8 0 3\n",
      " 2 2 5 6 9 9 4 1 5 4 2 3 6 4 8 5 9 5 7 8 9 4 8 1 5 4 4 9 6 1 8 6 0 4 5 2 7\n",
      " 4 6 4 5 6 0 3 2 3 6 7 1 5 1 4 7 6 8 8 5 5 1 6 2 8 8 9 9 7 6 2 2 2 3 4 8 8\n",
      " 3 6 0 9 7 7 0 1 0 4 5 1 5 3 6 0 4 1 0 0 3 6 5 9 7 3 5 5 9 9 8 5 3 3 2 0 5\n",
      " 8 3 4 0 2 4 6 4 3 4 5 0 5 2 1 3 1 4 1 1 7 0 1 5 2 1 2 8 7 0 6 4 8 8 5 1 8\n",
      " 4 5 8 7 9 8 5 0 6 2 0 7 9 8 9 5 2 7 7 1 8 7 4 3 8 3 5 6 0 0 3 0 5 0 0 4 1\n",
      " 2 8 4 5 9 6 3 1 8 8 4 2 3 8 9 8 8 5 0 6 3 3 7 1 6 4 1 2 1 1 6 4 7 4 8 3 4\n",
      " 0 5 1 9 4 5 7 6 3 7 0 5 9 7 5 9 7 4 2 1 9 0 7 5 3 3 6 3 9 6 9 5 0 1 5 5 8\n",
      " 3 3 6 2 6 5 5 2 0 8 7 3 7 0 2 2 3 5 8 7 3 6 5 9 9 2 5 6 3 0 7 1 1 9 6 1 1\n",
      " 0 0 2 9 3 9 9 3 7 7 1 3 5 4 6 1 2 1 1 8 7 6 9 2 0 4 4 8 8 7 1 3 1 7 1 9 5\n",
      " 1 7 0 0 2 2 6 9 4 1 9 0 6 7 7 9 5 4 7 0 7 6 8 7 1 4 6 2 8 7 5 9 0 3 9 6 6\n",
      " 1 9 8 2 9 8 9 7 4 8 5 5 9 7 7 6 8 1 3 5 7 9 5 5 2 1 1 2 2 4 8 7 5 8 8 9 4\n",
      " 9 0 1 1 8 9 3 4 2 9 1 7 3 3 3 1 7 6 3 0 6 5 2 3 5 7 8 0 9 5 2 2 1 4 1 8 2\n",
      " 4 1 6 2 0 8 1 0 6 9 7 7 8 2 3 2 6 9 5 7 1 4 8 1 2 9 3 4 8 4 0 3 5 1 8 1 5\n",
      " 0 3 0 2 4 1 1 0 3 9 2 6 0 4 6 6 5 4 0 3 8 6 6 4 1 5 7 4 0 5 4 8 9 7 0 4 7\n",
      " 6 3 3 4 8 8 1 6 5 9 3 2 2 1 8 2 7 6 0 4 3 0 8 2 6 2 1 6 3 8 2 6 7 5 5 6 9\n",
      " 1 8 9 4 6 4 6 1 4 0 2 9 8 6 0 6 5 6 9 0 3 5 6 7 4 3 0 9 2 0 8 1 2 7 0 7 0\n",
      " 7 3 6 3 4 9 2 4 3 4 9 6 6 2 7 8 5 3 3 3 5 1 9 6 5 8 2 0 7 3 9 6 7 2 1 0 1\n",
      " 4 3 2 2 5 3 3 3 3 8 0 7 6 5 7 9 4 9 6 8 4 6 7 1 8 6 8 3 6 0 2 8 3 6 1 1 5\n",
      " 2 8 5 9 6 1 6 3 5 1 5 4 8 9 0 1 7 1 2 9 8 3 1 4 3 5 6 6 7 3 4 7 7 4 0 5 6\n",
      " 6 1 8 6 2 9 8 1 8 5 2]\n",
      "The error percentage for zero images is 5.0%\n",
      "The error percentage for one images is 30.0%\n",
      "The error percentage for two images is 8.0%\n",
      "The error percentage for three images is 26.0%\n",
      "The error percentage for four images is 11.0%\n",
      "The error percentage for five images is 31.0%\n",
      "The error percentage for six images is 17.0%\n",
      "The error percentage for seven images is 9.0%\n",
      "The error percentage for eight images is 30.0%\n",
      "The error percentage for nine images is 25.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = digits['data']\n",
    "y = digits['target']\n",
    "\n",
    "# Split the data set in half\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5, train_size=0.5,  random_state=42)\n",
    "\n",
    "# Create decision tree\n",
    "clf = DecisionTreeClassifier(max_depth = 7, random_state=0)\n",
    "\n",
    "# Train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make Predicton\n",
    "prediction = clf.predict(X_test)\n",
    "print(prediction)\n",
    "print(y_test)\n",
    "\n",
    "# Variables for calculating error\n",
    "correct_prediction = None\n",
    "general_correct = 0\n",
    "general_incorrect = 0\n",
    "\n",
    "correct_1 = 0\n",
    "incorrect_1 = 0\n",
    "\n",
    "correct_2 = 0\n",
    "incorrect_2 = 0\n",
    "\n",
    "correct_3 = 0\n",
    "incorrect_3 = 0\n",
    "\n",
    "correct_4 = 0\n",
    "incorrect_4 = 0\n",
    "\n",
    "correct_5 = 0\n",
    "incorrect_5 = 0\n",
    "\n",
    "correct_6 = 0\n",
    "incorrect_6 = 0\n",
    "\n",
    "correct_7 = 0\n",
    "incorrect_7 = 0\n",
    "\n",
    "correct_8 = 0\n",
    "incorrect_8 = 0\n",
    "\n",
    "correct_9 = 0\n",
    "incorrect_9 = 0\n",
    "\n",
    "correct_10 = 0\n",
    "incorrect_10 = 0\n",
    "\n",
    "bruh = [1,2,3,4,5,6]\n",
    "\n",
    "# Iterates through the prediction array and test array and compares them for accuracy\n",
    "for i in range(len(y_test)):\n",
    "    # Determines if prediciton is True or False\n",
    "    if (prediction[i] == y_test[i]):\n",
    "        correct_prediction = True\n",
    "        general_correct += 1\n",
    "    else:\n",
    "        correct_prediction = False\n",
    "        general_incorrect += 1\n",
    "        \n",
    "    # Calculates the error of each number\n",
    "    \n",
    "    # For 1\n",
    "    if (y_test[i] == 0 and correct_prediction):\n",
    "        correct_1 += 1\n",
    "    elif (y_test[i] == 0 and correct_prediction == False):\n",
    "        incorrect_1 += 1\n",
    "        \n",
    "    # For 2\n",
    "    if (y_test[i] == 1 and correct_prediction):\n",
    "        correct_2 += 1\n",
    "    elif (y_test[i] == 1 and correct_prediction == False):\n",
    "        incorrect_2 += 1\n",
    "        \n",
    "    # For 3    \n",
    "    if (y_test[i] == 2 and correct_prediction):\n",
    "        correct_3 += 1\n",
    "    elif (y_test[i] == 2 and correct_prediction == False):\n",
    "        incorrect_3 += 1\n",
    "        \n",
    "    # For 4 \n",
    "    if (y_test[i] == 3 and correct_prediction):\n",
    "        correct_4 += 1\n",
    "    elif (y_test[i] == 3 and correct_prediction == False):\n",
    "        incorrect_4 += 1\n",
    "    \n",
    "    # For 5\n",
    "    if (y_test[i] == 4 and correct_prediction):\n",
    "        correct_5 += 1\n",
    "    elif (y_test[i] == 4 and correct_prediction == False):\n",
    "        incorrect_5 += 1\n",
    "    \n",
    "    # For 6\n",
    "    if (y_test[i] == 5 and correct_prediction):\n",
    "        correct_6 += 1\n",
    "    elif (y_test[i] == 5 and correct_prediction == False):\n",
    "        incorrect_6 += 1\n",
    "    \n",
    "    # For 7\n",
    "    if (y_test[i] == 6 and correct_prediction):\n",
    "        correct_7 += 1\n",
    "    elif (y_test[i] == 6 and correct_prediction == False):\n",
    "        incorrect_7 += 1\n",
    "        \n",
    "    # For 8  \n",
    "    if (y_test[i] == 7 and correct_prediction):\n",
    "        correct_8 += 1\n",
    "    elif (y_test[i] == 7 and correct_prediction == False):\n",
    "        incorrect_8 += 1\n",
    "    \n",
    "    # For 9 \n",
    "    if (y_test[i] == 8 and correct_prediction):\n",
    "        correct_9 += 1\n",
    "    elif (y_test[i] == 8 and correct_prediction == False):\n",
    "        incorrect_9 += 1\n",
    "    \n",
    "    # For 10\n",
    "    if (y_test[i] == 9 and correct_prediction):\n",
    "        correct_10 += 1\n",
    "    elif (y_test[i] == 9 and correct_prediction == False):\n",
    "        incorrect_10 += 1\n",
    "        \n",
    "\n",
    "\n",
    "# For 1\n",
    "print(f\"The error percentage for zero images is {round(incorrect_1 / (correct_1 + incorrect_1), 2) * 100}%\")\n",
    "\n",
    "# For 2\n",
    "print(f\"The error percentage for one images is {round(incorrect_2 / (correct_2 + incorrect_2), 1) * 100}%\")\n",
    "\n",
    "# For 3\n",
    "print(f\"The error percentage for two images is {round(incorrect_3 / (correct_3 + incorrect_3), 2) * 100}%\")\n",
    "\n",
    "# For 4\n",
    "print(f\"The error percentage for three images is {round(incorrect_4 / (correct_4 + incorrect_4), 2) * 100}%\")\n",
    "\n",
    "# For 5\n",
    "print(f\"The error percentage for four images is {round(incorrect_5 / (correct_5 + incorrect_5), 2) * 100}%\")\n",
    "\n",
    "# For 6\n",
    "print(f\"The error percentage for five images is {round(incorrect_6 / (correct_6 + incorrect_6), 2) * 100}%\")\n",
    "\n",
    "# For 7\n",
    "print(f\"The error percentage for six images is {round(incorrect_7 / (correct_7 + incorrect_7), 2) * 100}%\")\n",
    "\n",
    "# For 8\n",
    "print(f\"The error percentage for seven images is {round(incorrect_8 / (correct_8 + incorrect_8), 2) * 100}%\")\n",
    "\n",
    "# For 9\n",
    "print(f\"The error percentage for eight images is {round(incorrect_9 / (correct_9 + incorrect_9), 2) * 100}%\")\n",
    "\n",
    "# For 10\n",
    "print(f\"The error percentage for nine images is {round(incorrect_10 / (correct_10 + incorrect_10), 2) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc9c8109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit with the most error is five at 31.0% error.\n",
      "The error percentage for digit one and digit eight have the second most error at 30.0% error.\n",
      "The lowest amount of error was 5.0% error and that was for the zero images.\n",
      "The second least error is 8.0% for the two images.\n",
      "The overall error percentage is 19.0%\n",
      "The total number of correct predictions is 725\n",
      "Total total number of incorrect predictions is 174\n",
      "The amount of guesses it had to make is 899\n",
      "Overall, I don't think it was perfect, but I do think it was very accurate with over a 30% accuracy rate.\n",
      "If it was getting a grade it would get a B which is well above passing.S\n"
     ]
    }
   ],
   "source": [
    "print(\"The digit with the most error is five at 31.0% error.\")\n",
    "print(\"The error percentage for digit one and digit eight have the second most error at 30.0% error.\")\n",
    "print(\"The lowest amount of error was 5.0% error and that was for the zero images.\")\n",
    "print(\"The second least error is 8.0% for the two images.\")\n",
    "\n",
    "# General\n",
    "print(f\"The overall error percentage is {round(general_incorrect / len(y_test), 2) * 100}%\")\n",
    "\n",
    "# General Error\n",
    "print(\"The total number of correct predictions is\", general_correct)\n",
    "print(\"Total total number of incorrect predictions is\", general_incorrect)\n",
    "print(\"The amount of guesses it had to make is\", len(y_test))\n",
    "print(\"Overall, I don't think it was perfect, but I do think it was very accurate with over a 30% accuracy rate.\")\n",
    "print(\"If it was getting a grade it would get a B which is well above passing.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54a40ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4\n",
      "Score for 1 neighbor [0.96111111 0.95277778 0.96657382 0.98607242 0.95543175]\n",
      "Score for 3 neighbors [0.95555556 0.95833333 0.96657382 0.98607242 0.96657382]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\hamil\\Documents\\Programming\\anacondaz\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for 6 neighbors [0.94444444 0.95833333 0.96657382 0.97493036 0.95264624]\n",
      "Score for 9 neighbors [0.93055556 0.95277778 0.97214485 0.97771588 0.94986072]\n",
      "The max depth is 10.\n",
      "[0.775      0.725      0.80222841 0.84958217 0.78272981]\n",
      "From my results, I found that the K-NN classifier yielded better results than Decision trees.\n",
      "The number of neighbors does not really matter when comparing the K-NN classifier to decision trees.\n",
      "This is because the K-NN classifier in my testing always had higher testing regardless of the amount of neighbors\n",
      "None of the values of K really gave me the best results. I ran 4 different test changing K to 1, than 3, than 6, than 9.\n",
      "After testing each K-NN  classifier with different neighbors.\n",
      "My testing revealed that in this testing case the number of neighbors did not affect the accuracy of the 5-fold cross valdiation.\n",
      "Overall, changing the number of neighbors did not affect the accuracy of my K-NN classifier and in all of my test the K-NN had higher accuracy than decision trees regardless of it's number of neighbors.\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 4\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "x = digits['data']\n",
    "y = digits['target']\n",
    "\n",
    "# 1 Neighbor\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "print(\"Score for 1 neighbor\", cross_val_score(neigh, x, y, cv=5))\n",
    "\n",
    "# 3 Neighbor\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "print(\"Score for 3 neighbors\", cross_val_score(neigh, x, y, cv=5))\n",
    "\n",
    "# 6 Neighbor\n",
    "neigh = KNeighborsClassifier(n_neighbors=6)\n",
    "print(\"Score for 6 neighbors\", cross_val_score(neigh, x, y, cv=5))\n",
    "\n",
    "# 9 Neighbor\n",
    "neigh = KNeighborsClassifier(n_neighbors=9)\n",
    "print(\"Score for 9 neighbors\", cross_val_score(neigh, x, y, cv=5))\n",
    "\n",
    "# Decision Tree\n",
    "clf = DecisionTreeClassifier(max_depth = 10, random_state=0)\n",
    "print(\"The max depth is 10.\")\n",
    "print(cross_val_score(clf, x, y, cv=5))\n",
    "\n",
    "print(\"From my results, I found that the K-NN classifier yielded better results than Decision trees.\")\n",
    "print(\"The number of neighbors does not really matter when comparing the K-NN classifier to decision trees.\")\n",
    "print(\"This is because the K-NN classifier in my testing always had higher testing regardless of the amount of neighbors\")\n",
    "print(\"None of the values of K really gave me the best results. I ran 4 different test changing K to 1, than 3, than 6, than 9.\")\n",
    "print(\"After testing each K-NN  classifier with different neighbors.\")\n",
    "print(\"My testing revealed that in this testing case the number of neighbors did not affect the accuracy of the 5-fold cross valdiation.\")\n",
    "print(\"Overall, changing the number of neighbors did not affect the accuracy of my K-NN classifier and in all of my test the K-NN had higher accuracy than decision trees regardless of it's number of neighbors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c5e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
